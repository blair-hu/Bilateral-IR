{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA, sparse_encode\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "\n",
    "import warnings\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DataUse = sio.loadmat('AllSubs_feats_reprocessed.mat')\n",
    "DataUse = sio.loadmat('Z:\\Lab Member Folders\\Blair Hu\\Git Sandbox\\Aim-1-Bilateral-Exoskeleton-Intent-Recognition\\Data\\AllSubs_feats_reprocessed.mat')\n",
    "phaseinc = 0 # Specifies whether data from both legs are merged (0 = not merged, 2= merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The feats element has 5 columns, corresponding to delays of 0, 30, 60, 90, 120 ms\n",
    "filestr = '0Delay' # For saved filename\n",
    "feats_all = np.array(DataUse['feats_combined'][0,0]) # The column specifies which delay to use\n",
    "legphases_all = np.array(DataUse['legphase_combined'])\n",
    "trig_all = np.array(DataUse['trig_combined'])\n",
    "subject_all = np.array(DataUse['subject_combined'])\n",
    "\n",
    "# Get the entering and leaving modes from the triggers\n",
    "mode_all = np.empty(trig_all.shape)\n",
    "mode_leave = np.empty(trig_all.shape)\n",
    "for i in range(trig_all.shape[0]):\n",
    "    mode_all[i] = int(trig_all[i][0][0][2])\n",
    "    mode_leave[i] = int(trig_all[i][0][0][0])\n",
    "\n",
    "# Convert subject codes to numbers (1-10)\n",
    "subjectnum_all = np.empty(subject_all.shape)\n",
    "for i in range(subject_all.shape[0]):\n",
    "    if str(subject_all[i][0][0]) == 'AB156':\n",
    "        subjectnum_all[i] = 1\n",
    "    elif str(subject_all[i][0][0]) == 'AB185':\n",
    "        subjectnum_all[i] = 2\n",
    "    elif str(subject_all[i][0][0]) == 'AB186':\n",
    "        subjectnum_all[i] = 3\n",
    "    elif str(subject_all[i][0][0]) == 'AB188':\n",
    "        subjectnum_all[i] = 4\n",
    "    elif str(subject_all[i][0][0]) == 'AB189':\n",
    "        subjectnum_all[i] = 5\n",
    "    elif str(subject_all[i][0][0]) == 'AB190':\n",
    "        subjectnum_all[i] = 6\n",
    "    elif str(subject_all[i][0][0]) == 'AB191':\n",
    "        subjectnum_all[i] = 7\n",
    "    elif str(subject_all[i][0][0]) == 'AB192':\n",
    "        subjectnum_all[i] = 8\n",
    "    elif str(subject_all[i][0][0]) == 'AB193':\n",
    "        subjectnum_all[i] = 9\n",
    "    elif str(subject_all[i][0][0]) == 'AB194':\n",
    "        subjectnum_all[i] = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Remove non-walking trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove non-walking gait events\n",
    "keepinds = np.asarray([i for i in np.arange(len(mode_all)) if ((0 < mode_all[i] < 6) & (0 < mode_leave[i] < 6))])\n",
    "\n",
    "feats_all = feats_all[keepinds,:]\n",
    "legphases_all = legphases_all[keepinds]\n",
    "subject_all = subject_all[keepinds]\n",
    "trig_all = trig_all[keepinds]\n",
    "subjectnum_all = subjectnum_all[keepinds]\n",
    "mode_all = mode_all[keepinds]\n",
    "mode_leave = mode_leave[keepinds]\n",
    "\n",
    "# Encode class as one-hot for ANN\n",
    "onehotmode = np.zeros((mode_all.shape[0],5))\n",
    "for i in range(mode_all.shape[0]):\n",
    "    onehotmode[i,int(mode_all[i])-1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the number of gait events for each leg for each subject (after removal of standing transitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC:\n",
      "516.55\n",
      "47.4904990498\n",
      "TO:\n",
      "522.65\n",
      "48.5296558817\n"
     ]
    }
   ],
   "source": [
    "subjsteps = np.empty((10,4))\n",
    "for phaseind in range(1,5):\n",
    "    for subjind in range(1,11):\n",
    "        phase = np.where(legphases_all == phaseind)[0]\n",
    "        subj = np.where(subjectnum_all == subjind)[0]\n",
    "        subjsteps[subjind-1,phaseind-1] = len(np.intersect1d(phase,subj))\n",
    "\n",
    "# Heel contact\n",
    "print('HC:')\n",
    "print(np.mean(np.hstack((subjsteps[:,0],subjsteps[:,2]))))\n",
    "print(np.std(np.hstack((subjsteps[:,0],subjsteps[:,2]))))\n",
    "\n",
    "# Toe off\n",
    "print('TO:')\n",
    "print(np.mean(np.hstack((subjsteps[:,1],subjsteps[:,3]))))\n",
    "print(np.std(np.hstack((subjsteps[:,1],subjsteps[:,3]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define feature sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make feature sets from labels\n",
    "featlabels = DataUse['featlabels']\n",
    "imufeats = np.arange(0,180)\n",
    "goniofeats = np.arange(180,228)\n",
    "emgfeats = np.arange(228,368)\n",
    "ipsifeats = []\n",
    "contrafeats = []\n",
    "waistfeats = []\n",
    "LLemgfeats = []\n",
    "ULemgfeats = []\n",
    "shankfeats = []\n",
    "thighfeats = []\n",
    "kneefeats = []\n",
    "anklefeats = []\n",
    "\n",
    "LLemg = ['TA','MG','SOL']\n",
    "ULemg = ['BF','ST','RF','VL']\n",
    "\n",
    "for i in range(featlabels.shape[0]):\n",
    "    if 'Ipsi' in str(featlabels[i]):\n",
    "        ipsifeats.append(i)\n",
    "    if 'Contra' in str(featlabels[i]):\n",
    "        contrafeats.append(i)\n",
    "    if  'Waist' in str(featlabels[i]):\n",
    "        waistfeats.append(i)\n",
    "    if any(muscles in str(featlabels[i]) for muscles in LLemg):\n",
    "        LLemgfeats.append(i)\n",
    "    if any(muscles in str(featlabels[i]) for muscles in ULemg):\n",
    "        ULemgfeats.append(i)\n",
    "    if 'Shank' in str(featlabels[i]):\n",
    "        shankfeats.append(i)\n",
    "    if 'Thigh' in str(featlabels[i]):\n",
    "        thighfeats.append(i)\n",
    "    if 'Knee' in str(featlabels[i]):\n",
    "        kneefeats.append(i)\n",
    "    if 'Ankle' in str(featlabels[i]):\n",
    "        anklefeats.append(i)\n",
    "\n",
    "ipsifeats = np.array(ipsifeats)\n",
    "contrafeats = np.array(contrafeats)\n",
    "waistfeats = np.array(waistfeats)\n",
    "\n",
    "ipsi_emg = np.intersect1d(emgfeats,ipsifeats)\n",
    "ipsi_gonio = np.intersect1d(goniofeats,ipsifeats)\n",
    "ipsi_imu = np.intersect1d(imufeats,ipsifeats)\n",
    "ipsi_all = ipsifeats\n",
    "\n",
    "ipsi_emg_gonio = np.union1d(ipsi_emg,ipsi_gonio)\n",
    "ipsi_emg_imu = np.union1d(ipsi_emg,ipsi_imu)\n",
    "ipsi_gonio_imu = np.union1d(ipsi_gonio,ipsi_imu)\n",
    "\n",
    "contra_emg = np.intersect1d(emgfeats,contrafeats)\n",
    "contra_gonio = np.intersect1d(goniofeats,contrafeats)\n",
    "contra_imu = np.intersect1d(imufeats,contrafeats)\n",
    "contra_all = contrafeats\n",
    "\n",
    "ipsi_all_contra_emg = np.union1d(ipsi_all,contra_emg)\n",
    "ipsi_all_contra_gonio = np.union1d(ipsi_all,contra_gonio)\n",
    "ipsi_all_contra_imu = np.union1d(ipsi_all,contra_imu)\n",
    "\n",
    "ipsi_all_contra_emg_gonio = np.union1d(ipsi_all_contra_emg,contra_gonio)\n",
    "ipsi_all_contra_emg_imu = np.union1d(ipsi_all_contra_emg,contra_imu)\n",
    "ipsi_all_contra_gonio_imu = np.union1d(ipsi_all_contra_gonio,contra_imu)\n",
    "\n",
    "bilat_emg = emgfeats\n",
    "bilat_gonio = goniofeats\n",
    "bilat_imu = np.union1d(ipsi_imu,contra_imu)\n",
    "bilat_all = np.union1d(np.union1d(bilat_emg,bilat_gonio),bilat_imu)\n",
    "\n",
    "# Added these sensor sets for full comparison\n",
    "ipsi_LLemg = np.intersect1d(LLemgfeats,ipsifeats) \n",
    "ipsi_ULemg = np.intersect1d(ULemgfeats,ipsifeats) \n",
    "contra_LLemg = np.intersect1d(LLemgfeats,contrafeats) \n",
    "contra_ULemg = np.intersect1d(ULemgfeats,contrafeats) \n",
    "ipsi_emg_contra_LLemg = np.union1d(ipsi_emg,contra_LLemg) \n",
    "ipsi_emg_contra_ULemg = np.union1d(ipsi_emg,contra_ULemg) \n",
    "\n",
    "ipsi_knee = np.intersect1d(kneefeats,ipsifeats) \n",
    "ipsi_ankle = np.intersect1d(anklefeats,ipsifeats) \n",
    "contra_knee = np.intersect1d(kneefeats,contrafeats) \n",
    "contra_ankle = np.intersect1d(anklefeats,contrafeats) \n",
    "ipsi_gonio_contra_knee = np.union1d(ipsi_gonio,contra_knee)  \n",
    "ipsi_gonio_contra_ankle = np.union1d(ipsi_gonio,contra_ankle) \n",
    "\n",
    "ipsi_shank = np.intersect1d(shankfeats,ipsifeats) \n",
    "ipsi_thigh = np.intersect1d(thighfeats,ipsifeats) \n",
    "contra_shank = np.intersect1d(shankfeats,contrafeats) \n",
    "contra_thigh = np.intersect1d(thighfeats,contrafeats)\n",
    "ipsi_imu_contra_shank = np.union1d(ipsi_imu,contra_shank) \n",
    "ipsi_imu_contra_thigh = np.union1d(ipsi_imu,contra_thigh) \n",
    "\n",
    "featsdict = {'1': ipsi_emg, '2': ipsi_gonio, '3': ipsi_imu, '4': ipsi_emg_gonio, '5': ipsi_emg_imu, '6': ipsi_gonio_imu,\n",
    "             '7': ipsi_all, '8': ipsi_all_contra_emg, '9': ipsi_all_contra_gonio, '10': ipsi_all_contra_imu, \n",
    "             '11': ipsi_all_contra_emg_gonio, '12': ipsi_all_contra_emg_imu, '13': ipsi_all_contra_gonio_imu,\n",
    "             '14': bilat_emg, '15': bilat_gonio, '16': bilat_imu, '17': bilat_all, '18': ipsi_LLemg, '19': ipsi_ULemg, \n",
    "             '20': ipsi_emg_contra_LLemg, '21': ipsi_emg_contra_ULemg, '22': ipsi_knee, '23': ipsi_ankle, '24': ipsi_gonio_contra_knee, '25': ipsi_gonio_contra_ankle,\n",
    "             '26': ipsi_shank, '27': ipsi_thigh, '28': ipsi_imu_contra_shank, '29': ipsi_imu_contra_thigh, '30': contra_emg, '31': contra_gonio, '32': contra_imu, '33': contra_all}\n",
    "\n",
    "featskeys = ('1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33')\n",
    "sensorsets = len(featskeys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Define Scale, Dimensionality Reduction, Pipelines, CV, and Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "svm = SVC(kernel = 'linear', C = 10)\n",
    "ann = MLPClassifier(solver = 'sgd', hidden_layer_sizes = (10,), max_iter = 1000, learning_rate_init = .1, learning_rate = 'adaptive', momentum = 0.9)\n",
    "\n",
    "scale = preprocessing.StandardScaler()\n",
    "scale_PCA = Pipeline([('norm',scale),('dimred',pca)])\n",
    "\n",
    "# Define cross-validation parameters\n",
    "numfolds = 10\n",
    "kf = KFold(n_splits = numfolds, shuffle = True)\n",
    "skf = StratifiedKFold(n_splits = numfolds, shuffle = True)\n",
    "loo = LeaveOneOut()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Within Subjects Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjkeys = ('AB156','AB185','AB186','AB188','AB189','AB190','AB191','AB192','AB193','AB194')\n",
    "legphasekeys = ('RHC','RTO','LHC','LTO')\n",
    "\n",
    "for subnum in np.arange(1,11): # Iterate across subjects\n",
    "    print('Subject: ' + subjkeys[subnum-1])\n",
    "\n",
    "    withinresultsdict = {}\n",
    "    withinresultsdict[subjkeys[subnum-1]] = {'RHC':[],'RTO':[],'LHC':[],'LTO':[]}\n",
    "        \n",
    "    # Get indices corresponding to subnum\n",
    "    subjectspecific = np.asarray([i for i in range(len(subjectnum_all)) if subjectnum_all[i] == subnum])  \n",
    "        \n",
    "    # If phaseinc = 0, then each leg has its own classifier for each gait event; legphaseID should be 1,2,3,4\n",
    "    # If phaseinc = 2, then each gait event has its own classifier (legs combined); legphaseID should be 1,2\n",
    "    for legphaseID in np.array([1,2,3,4]): # Iterate across HC and TO\n",
    "        print('Leg Phase ID: ' + legphasekeys[legphaseID-1])\n",
    "                \n",
    "        phasespecific = np.asarray([j for j in range(len(legphases_all)) if ((legphases_all[j] == legphaseID) or (legphases_all[j] == (legphaseID + phaseinc)))])    \n",
    "        subjectlegphases = np.intersect1d(subjectspecific,phasespecific)\n",
    "\n",
    "        # Get the data corresponding to the gait phase        \n",
    "        legphasefeats_all = feats_all[subjectlegphases,:]\n",
    "        legphasemodeleave_all = mode_leave[subjectlegphases]\n",
    "        legphasemode_all = mode_all[subjectlegphases]\n",
    "        legphaseonehotmode_all = onehotmode[subjectlegphases,:]\n",
    "        legphasetrig_all = trig_all[subjectlegphases]      \n",
    "        \n",
    "        numtemp = np.shape(legphasemode_all)[0]\n",
    "        \n",
    "        # Last column for true mode\n",
    "        pred_temp = np.empty((numtemp,4*sensorsets+1))\n",
    "\n",
    "        for modeclassifier in np.array([1,2,3,4,5]): # Iterate across LW, RA, RD, SA, SD           \n",
    "            ms_inds = np.where(legphasemodeleave_all == modeclassifier)[0]\n",
    "            ms_feats = legphasefeats_all[ms_inds,:]\n",
    "            ms_mode = legphasemode_all[ms_inds]\n",
    "            ms_onehotmode = legphaseonehotmode_all[ms_inds,:]\n",
    "            ms_trig = legphasetrig_all[ms_inds]\n",
    "\n",
    "            print\n",
    "            print('Mode: ' + str(modeclassifier))\n",
    "            print('Unique: ' + str(np.unique(ms_mode)))\n",
    "            print np.histogram(ms_mode,bins=[0, 1.5, 2.5, 3.5, 4.5, 5.5])[0]            \n",
    "            \n",
    "            print('Instances: ' + str(len(ms_inds)))\n",
    "            \n",
    "            foldcounter = 0\n",
    "            for train_index, test_index in kf.split(ms_feats):    \n",
    "#             for train_index, test_index in skf.split(ms_feats,ms_mode.ravel()): \n",
    "#             for train_index, test_index in loo.split(ms_feats):\n",
    "                foldcounter += 1\n",
    "                print('Fold: ' + str(foldcounter))\n",
    "\n",
    "                # Make training and testing sets\n",
    "                feats_train, mode_train, onehotmode_train, trig_train = ms_feats[train_index,:], ms_mode[train_index], ms_onehotmode[train_index,:], ms_trig[train_index]\n",
    "                feats_test, mode_test, onehotmode_test, trig_test = ms_feats[test_index,:], ms_mode[test_index], ms_onehotmode[test_index,:], ms_trig[test_index]     \n",
    "\n",
    "                # Iterate across all sensor sets\n",
    "                for keyind in np.arange(sensorsets):\n",
    "                    featskeystemp = featskeys[keyind]\n",
    "                    usefeats = featsdict[featskeystemp]\n",
    "                    \n",
    "                    scale.fit(feats_train[:,usefeats])\n",
    "                    scale_PCA.fit(feats_train[:,usefeats])\n",
    "                    \n",
    "                    feats_train_norm = scale.transform(feats_train[:,usefeats])\n",
    "                    feats_train_PCA = scale_PCA.transform(feats_train[:,usefeats])\n",
    "\n",
    "                    feats_test_norm = scale.transform(feats_test[:,usefeats])\n",
    "                    feats_test_PCA = scale_PCA.transform(feats_test[:,usefeats])           \n",
    "                    \n",
    "                    pcaexplainedvar = np.cumsum(scale_PCA.named_steps['dimred'].explained_variance_ratio_)                \n",
    "                    pcanumcomps = min(min(np.where(pcaexplainedvar > 0.95))) + 1\n",
    "                    \n",
    "                    unique_modes = np.unique(mode_train)\n",
    "\n",
    "                    lda.set_params(priors = np.ones(len(unique_modes))/len(unique_modes))\n",
    "\n",
    "                    pcaldafit = lda.fit(feats_train_PCA[:,0:pcanumcomps],mode_train.ravel())\n",
    "                    pred_temp[ms_inds[test_index],keyind] = pcaldafit.predict(feats_test_PCA[:,0:pcanumcomps]).ravel()\n",
    "\n",
    "                    #####\n",
    "                    # Use dimensionality reduced feature set for SVM and ANN\n",
    "                    #####\n",
    "                    \n",
    "                    # svmfit = svm.fit(feats_train_PCA[:,0:pcanumcomps],mode_train)\n",
    "                    # pred_temp[ms_inds[test_index],int(featskeystemp)-1+17] = svmfit.predict(feats_test_PCA[:,0:pcanumcomps]).ravel()\n",
    "\n",
    "                    # annfit = ann.fit(feats_train_PCA[:,0:pcanumcomps],onehotmode_train)            \n",
    "                    # pred_temp[ms_inds[test_index],int(featskeystemp)-1+34] = (np.argmax(annfit.predict(feats_test_PCA[:,0:pcanumcomps]),axis=1)+1).ravel()\n",
    "\n",
    "                    svmfit = svm.fit(feats_train_norm,mode_train.ravel())\n",
    "                    pred_temp[ms_inds[test_index],keyind+sensorsets] = svmfit.predict(feats_test_norm).ravel()\n",
    "\n",
    "                    annfit = ann.fit(feats_train_norm,onehotmode_train)      \n",
    "                    pred_temp[ms_inds[test_index],keyind+2*sensorsets] = (np.argmax(annfit.predict(feats_test_norm),axis=1)+1).ravel()\n",
    "\n",
    "                    ########################################\n",
    "                    # Sparse representation classification #\n",
    "                    ########################################\n",
    "                    # L2-normalize features\n",
    "                    feats_train_l2norm = preprocessing.normalize(feats_train_PCA[:,0:pcanumcomps],norm='l2',axis=1)\n",
    "                    feats_test_l2norm = preprocessing.normalize(feats_test_PCA[:,0:pcanumcomps],norm='l2',axis=1)\n",
    "                    \n",
    "                    dictionary = feats_train_l2norm\n",
    "                    \n",
    "                    # Get binary class masks (only 1 for dictionary elements corresponding to that class)\n",
    "                    class_matrix = {}\n",
    "                    for label in np.unique(mode_train):\n",
    "                        label_inds = np.asarray([ind for ind in np.arange(len(train_index)) if mode_train[ind] == label])\n",
    "                        label_mask = np.zeros(np.shape(feats_train_l2norm))\n",
    "                        if len(label_inds) > 0:\n",
    "                            label_mask[label_inds,:] = 1\n",
    "                            class_matrix[str(label)] = np.multiply(dictionary,label_mask)\n",
    "                        else:\n",
    "                            class_matrix[str(label)] = np.multiply(dictionary,label_mask)\n",
    "                    \n",
    "                    # Perform classification based on class with lowest reconstruction error\n",
    "                    src_pred = np.empty((len(test_index),1))\n",
    "                    for pred_inds in np.arange(len(test_index)):\n",
    "                        feats_pred = feats_test_l2norm[pred_inds,:]\n",
    "                        code = sparse_encode(X=feats_pred.reshape(1,-1),dictionary=dictionary,algorithm='omp',alpha=1)\n",
    "                        resid = []\n",
    "                        for label in np.unique(mode_train):\n",
    "                            resid.append(np.linalg.norm(np.subtract(np.dot(code,class_matrix[str(label)]),feats_pred),ord=2))\n",
    "                        src_pred[pred_inds] = np.unique(mode_train)[resid.index(min(resid))]\n",
    "\n",
    "                    pred_temp[ms_inds[test_index],keyind+3*sensorsets] = src_pred.ravel()\n",
    "                    ########################################\n",
    "                \n",
    "        pred_temp[:,4*sensorsets] = legphasemode_all.ravel()\n",
    "\n",
    "        # Save predictions and triggers for all sensor sets\n",
    "        withinresultsdict[subjkeys[subnum-1]][legphasekeys[legphaseID-1]] = {'Pred':[],'Trig':[]}        \n",
    "        withinresultsdict[subjkeys[subnum-1]][legphasekeys[legphaseID-1]]['Pred'] = pred_temp\n",
    "        withinresultsdict[subjkeys[subnum-1]][legphasekeys[legphaseID-1]]['Trig'] = legphasetrig_all\n",
    "            \n",
    "        print    \n",
    "        print('...Finished ' + subjkeys[subnum-1] + ' ' + legphasekeys[legphaseID-1] + '...')\n",
    "        \n",
    "    # Save predictions and triggers for the subnum\n",
    "#     sio.savemat(subjkeys[subnum-1] + '_WithinSubjectResults_' + filestr + '_ModeSpecific_AllSensorsClassifiers_LOO',withinresultsdict)\n",
    "    sio.savemat(subjkeys[subnum-1] + '_WithinSubjectResults_' + filestr + '_ModeSpecific_AllSensorsClassifiers_' + str(numfolds) + 'Fold_Reprocessed',withinresultsdict)\n",
    "    \n",
    "    print('...File saved...')    \n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check the results of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(withinresultsdict['AB186']['RHC']['Pred'][:,132],withinresultsdict['AB186']['RHC']['Pred'][:,15])\n",
    "print cm\n",
    "print np.double(np.sum(cm.diagonal()))/np.sum(np.sum(cm))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
